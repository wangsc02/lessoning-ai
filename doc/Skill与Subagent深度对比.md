# 我花了一周时间才搞懂：Skill 和 Subagent 到底有什么区别？

> **TL;DR**：如果你在纠结"该写 Skill 还是用 Subagent"，说明你还没理解它们的本质。这篇文章会彻底讲清楚。

---

## 一个困惑的开始

上周，我在用 Claude Code 开发时遇到了一个让我抓狂的问题：

我想让 AI 帮我审查代码，按照公司的编码规范。我有两个选择：

**选择A**：写一个 `code-review` Skill，把规范写进去
**选择B**：启动一个 Subagent，让它自己去审查

两种方式看起来都能完成任务，但我总觉得哪里不对劲。

- 用 Skill？感觉太简单了，就是个文档
- 用 Subagent？感觉太重了，只是审查代码而已

**我意识到：我根本不理解它们的本质区别。**

于是，我花了一周时间深挖 Claude Code 的实现机制、AI 系统架构，终于搞明白了。今天分享给你。

---

## 一个类比：让你秒懂本质差异

想象你开了一家餐厅，需要培训厨师做菜。

### 场景1：写操作手册（Skill）

你写了一本《川菜制作标准》：
- 麻婆豆腐：豆瓣酱要炒香，豆腐要嫩...
- 回锅肉：肉片薄厚 3mm，火候要大...
- 宫保鸡丁：花生米要炸脆，鸡丁要滑嫩...

**厨师怎么用？**
- 每次做菜前，翻一下手册
- 按照手册的步骤和标准做
- 做的过程中随时问你："这样对吗？"

**特点**：
- ✅ 标准统一，质量稳定
- ✅ 你全程可见，可以随时纠正
- ✅ 厨师做完一道菜，再做下一道（串行）
- ❌ 如果要做 10 道菜，需要 10 次操作

### 场景2：外包给团队（Subagent）

你把整个宴席外包给一个专业团队：
- 任务："做一桌川菜宴席，10 道菜"
- 团队自己决定：
  - 哪些菜先做，哪些后做
  - 谁负责哪道菜
  - 用什么锅、什么火候

**你怎么参与？**
- 只在开始时说明需求
- 团队在厨房里自己干活（你看不见过程）
- 完成后端出成品

**特点**：
- ✅ 效率高，可以并行做菜（3 个厨师同时开工）
- ✅ 你不需要逐步指导
- ❌ 中间过程不可见（黑盒）
- ❌ 如果方向错了，最后才知道

### 哪个更好？

**都不是！最好的方式是结合：**

**方式3：手册 + 团队（Skill + Subagent）**
- 你写了《川菜制作标准》手册（Skill）
- 把手册给外包团队（Subagent）
- 团队按照你的标准，高效完成宴席

**结果**：
- ✅ 标准统一（手册保证）
- ✅ 效率高（团队并行）
- ✅ 你只需要维护手册（简单）

**这就是 Skill + Subagent 的黄金组合！**

---

## 技术本质：为什么会有这种差异？

类比很形象，但要真正理解，还得看技术实现。

### Skill 的技术本质：上下文增强

```
你的对话 = [System Prompt] + [Skill 内容] + [对话历史]
                              ↑
                        这就是 Skill
```

**实现机制**：
1. 你创建一个 `code-review.md` 文件
2. 当你说"激活 code-review Skill"时
3. Claude 把这个文件的内容**注入**到指令/上下文中（可以粗略理解为 System Prompt 的一部分）
4. 之后的每次推理，都会"看到"这个 Skill

**关键点**：
- Skill 只是"文本内容"，不是独立程序
- 它和你的对话在**同一个上下文**中
- 每次推理都能"看到"对话历史

**类比**：就像你给厨师一本手册，他每次做菜都翻着手册看。

### Subagent 的技术本质：独立进程

```
主对话                  Subagent（独立）
┌────────┐             ┌──────────────┐
│ 你：审查 │  启动      │ 任务：审查代码 │
│ 代码    │─────────>│ 工具：Glob/Read │
│        │             │ [独立推理...]  │
│ [等待] │  返回结果   │ [完成]        │
│        │<───────────│              │
└────────┘             └──────────────┘
```

**技术深究（MCP 视角）**：
如果你关注 **Model Context Protocol (MCP)**，可以这样理解：
- **Skill** ≈ `MCP Resources`（静态资源注入）或 `MCP Prompts`（模板注入）
- **Subagent** ≈ `Client + MCP Tools Loop`（拥有独立工具循环的客户端）

**实现机制**：
1. 你调用 `Task(subagent_type="explore", prompt="审查代码")`
2. Claude 创建一个**独立的 AI 进程**
3. 这个进程有自己的推理循环，可以调用工具
4. 完成后返回结果，进程销毁

**关键点**：
- Subagent 是独立的"进程"，有自己的生命周期
- 它**看不到**你的对话历史（除非你显式传递）
- 它有自己的"决策权"，可以自主调用工具

**类比**：就像你雇了一个独立的厨师团队，他们在自己的厨房工作。

### 等等，Cursor Commands 呢？

在理解 Skill 和 Subagent 的过程中，我产生了一个困惑：

**Cursor 也提供了 Commands 能力**，同样是创建 `.md` 文件，在文件内写清楚执行流程。这和 Skill 看起来几乎一样啊？

经过深入思考，我发现了关键洞察：

**Cursor Commands 和 Claude Skills 本质上是同一类东西**——它们都是"AI 指令系统"：

```
核心机制：
Commands 和 Skills =
    将自然语言指令 → 注入到 AI 的上下文中 → 影响 AI 的行为

差异点：
┌─────────────────┬──────────────┬──────────────┐
│                 │ Commands     │ Skills       │
├─────────────────┼──────────────┼──────────────┤
│ 产品定位        │ IDE 自动化   │ AI 知识封装  │
│ 集成深度        │ Editor API   │ Context 增强 │
│ 使用场景        │ 代码编辑     │ 通用任务     │
└─────────────────┴──────────────┴──────────────┘
```

**关键认知**：这两者的差异主要在**产品设计哲学**上，而不是技术能力上。

**真正的架构差异是**：

```
层级1: 上下文增强（指令型）
├─ Claude Skills   ← 知识注入
└─ Cursor Commands ← 工作流注入

层级2: 独立进程（执行型）
└─ Subagent        ← 自主推理 + 工具调用
```

**所以正确的对比应该是**：

- **Skills/Commands** (同类): 教 AI "怎么想"和"按什么标准做"
- **Subagent** (独立类): 给 AI "独立的决策权"和"自主的执行能力"

这个认知很重要！它帮助我们理解：不要被产品名称迷惑，要看清技术本质。

---

## 七个维度，彻底理解差异

### 维度1：上下文（Context）

**Skill**：共享上下文

```
┌────────────────────────────┐
│ 同一个对话窗口              │
├────────────────────────────┤
│ User: "我们用 TypeScript"   │
│ User: "帮我写个工具函数"    │
│ AI (with Skill):           │
│   → 看到"用 TypeScript"     │
│   → 生成 .ts 代码           │
└────────────────────────────┘
```

**Subagent**：隔离上下文

```
主对话                  Subagent
┌────────────┐         ┌────────────┐
│ "我们用TS"  │         │ 任务：写函数 │
│            │ 启动     │ (看不到TS)  │
│ "写函数"    │────────>│ → 生成JS代码 │
└────────────┘         └────────────┘
                        ↑
                    需要显式告知上下文
```

**教训**：
- 用 Skill：AI 能理解对话中的"隐含信息"
- 用 Subagent：必须在任务描述中**明确所有上下文**

### 维度2：执行模式（Execution）

**Skill**：串行执行（阻塞）

```
Timeline:
t=0  审查文件A (等待 2秒)
t=2  审查文件B (等待 2秒)
t=4  审查文件C (等待 2秒)
总耗时：6秒
```

**Subagent**：并行执行（非阻塞）

```
Timeline:
t=0  启动3个Subagent (并行)
     ├─ Agent A: 文件A
     ├─ Agent B: 文件B
     └─ Agent C: 文件C
t=2  全部完成
总耗时：2秒 (快3倍)
```

**教训**：
- 单个任务 → Skill 更简单
- 批量任务 → Subagent 更高效（更准确地说：更擅长“并发/异步”推进任务）

**补充说明（更严谨）**：
- “并行/并发”是否真的能带来线性加速，取决于工具调用的限流（rate limit）、队列/配额、以及任务之间是否存在依赖。
- 很多时候你获得的是“并发 + 异步”，而不是 CPU 意义上的“真并行”；但对用户体验来说，依然是**不阻塞主对话**、总体吞吐更高。

### 维度3：生命周期（Lifecycle）

**Skill**：会话级持久

```
会话开始
  │
激活 Skill
  │
  ├─ 任务1 (Skill生效)
  ├─ 任务2 (Skill生效)
  └─ 任务3 (Skill生效)
  │
会话结束 (Skill失效)
```

**Subagent**：任务级临时

```
任务1
  │
启动 Subagent A
  │
完成 (A销毁)

任务2
  │
启动 Subagent B (全新)
  │
完成 (B销毁)
```

**教训**：
- 需要"模式切换"（如进入审查模式）→ Skill
- 一次性任务 → Subagent

### 维度4：可见性（Visibility）

**Skill**：完全透明

```
User: "审查这段代码"
AI (with Skill):
  ├─ "根据Skill，我先检查命名"
  ├─ "发现问题：变量名不规范"
  ├─ "再检查安全性"
  └─ "发现：SQL注入风险"
      ↑
  每一步都可见，可以随时打断
```

**Subagent**：黑盒执行

```
User: "审查这段代码"
Main: "启动Subagent..."
[Subagent内部]
  ├─ Glob找文件
  ├─ Read代码
  ├─ 分析问题
  └─ 生成报告
Main: "审查完成，这是报告"
      ↑
  只看到结果，看不到过程
```

**教训**：
- 需要实时调整 → Skill（透明）
- 只关注结果 → Subagent（高效）

### 维度5：工具使用（Tool Usage）

**Skill**：间接影响

```
Skill说："先用Glob找文件，再用Read读取"
主Agent理解后，调用工具
  ├─ Glob("**/*.ts")
  └─ Read("file.ts")

特点：
- Skill只是"建议"
- 主Agent决定是否执行
```

**Subagent**：自主决定

```
Subagent内部推理：
  "任务需要分析代码"
  → 决策：用Glob找文件
  → 调用 Glob("**/*.ts")
  "找到50个文件，太多了"
  → 决策：只读关键文件
  → 调用 Read("core.ts")

特点：
- 完全自主决策
- 动态调整策略
```

**教训**：
- 简单工作流 → Skill（指导）
- 复杂探索 → Subagent（自主）

### 维度6：Token 经济学（Cost）

**Skill**：按揭付费（持续通胀）

Skill 的内容会注入到 System Prompt。这意味着，**你的 Skill 越长，后续每一句对话的成本就越高**。

- 就像给厨师一本厚厚的字典，他每做一道菜都要把字典背一遍，脑力（Token）消耗极大。
- 如果 Skill 太大，会迅速挤占 Context Window，导致模型“遗忘”之前的对话。

**Subagent**：一次性买断（清爽）

Subagent 在独立环境运行，它的几千次中间思考（Chain of Thought）和工具调用，**不会计入你主对话的历史**。

- 就像外包团队在他们自己的办公室吵了一下午，最后只发给你一份确定的报告。你只需要为这一下午付费，不需要把他们的争吵记录永远背在身上。
- 保持主线程 Context 清爽，适合长任务。

**教训**：
- 高频、通用、短规则 → Skill
- 过程繁琐、中间产物无需保留 → Subagent

### 维度7：风险与控制（Risk & Control）

**Skill**：人机协同（Human-in-the-loop）

过程完全透明，且一步一步来，用户可以随时打断（Interruption）。
- 如果 AI 理解错了规范，用户下一句就能纠正。
- **风险低，容错率高**。

**Subagent**：失控风险（Runaway Loop）

因为是黑盒、独立进程，Subagent 容易陷入**死循环**或者**连锁幻觉**。
- 比如它可能会在一个错误的文件路径上死磕 10 次，直到耗尽 Token 或触发上限。
- **风险高，调试难**。

**教训**：
- 任务不确定性高、容易走偏 → Skill（人盯着做）
- 路径清晰、只是繁琐 → Subagent（放手去做）

---

## 工程化补充：让对比更能落地

上面的七个维度，足够你做日常选择。但如果你要把它写进团队规范，或者做企业级落地，下面这几块一定会被问到。

### 1）可观测性与调试（Observability / Debuggability）

**Skill**：更容易“现场调试”
- 你能在主对话里看到它每一步的解释与产出，出了问题可以即时纠偏。
- 调整成本低：改几行 Skill 文本，立刻就能验证效果。

**Subagent**：更像“分布式系统排障”
- 你往往只拿到最终结果，真正出问题的点可能发生在：文件选择、工具参数、推理分支、外部依赖、限流等任一环节。
- 更建议配套一套最小可观测能力：
  - 记录每次工具调用：输入参数、输出摘要、耗时、错误码
  - 给关键步骤打点：选了哪些文件/为什么、跳过了哪些/为什么
  - 支持“重放”：同一 prompt + 同一输入，尽量可复现结果

一句话：**Skill 靠“对话内纠偏”，Subagent 靠“日志 + trace + 重放”。**

### 2）安全与权限治理（Security / Governance）

当你引入工具调用（读文件、写文件、跑命令、访问网络）后，Subagent 的能力边界就变成了安全边界。

建议你在文档里明确三条“底线规则”（尤其面向企业）：
- **最小权限原则**：只开放必要的工具、路径、域名（allowlist），不要默认全开。
- **不信任外部输入**：把网页/文档/Issue/PR 评论等内容当“数据”，不要当“指令”，防 prompt injection。
- **敏感信息策略**：密钥/Token/PII 不回显；必要时做脱敏与分级；产出里避免复制敏感原文。

一句话：**Subagent 的“自主”必须被权限与策略框住。**

### 3）质量控制与验收（Quality Gate）

很多团队用 Subagent 失败，不是因为它做不到，而是因为缺少“验收标准”——结果好不好没人能一致判断。

一个很实用的做法：为 Subagent 输出设置“硬约束”：
- **输出结构固定**：例如按表格/JSON schema 输出（问题、严重级别、证据、建议、风险）
- **必须给证据**：至少包含文件路径 + 片段（或行号/定位方式），避免“空泛建议”
- **可复核**：允许抽样复查；Skill/Prompt 变更后，用一组回归样例对比前后差异

一句话：**没有验收标准的自动化 = 不可控的自动化。**

---

## 实战：我是怎么做选择的？

分享3个真实场景，看我怎么选。

### 场景1：生成技术文档

**需求**：为API接口生成文档

**我的选择**：Skill

**原因**：
```
✅ 文档格式固定（可以用Skill定义模板）
✅ 需要多轮交互（"这个参数是必填吗？"）
✅ 需要理解对话历史（"和上一个接口保持一致"）
❌ 不需要探索代码库
```

**实现**：
```markdown
# api-doc-generator.md
---
name: api-doc-generator
---
## Output Format
每个接口包含：
1. 接口说明
2. 参数列表
3. 响应示例
4. 错误码说明

## Writing Style
- 主动语态
- 避免术语
- 提供示例
```

### 场景2：分析代码库架构

**需求**：理解一个新项目的架构

**我的选择**：Subagent (Explore Agent)

**原因**：
```
✅ 需要探索整个代码库（Glob多次）
✅ 需要自主决策（读哪些文件、多深入）
✅ 耗时较长（不能阻塞主对话）
✅ 不依赖对话历史
```

**实现**：
```python (Pseudocode)
Task(
    subagent_type="explore",
    prompt="""
    分析这个项目的架构：
    1. 主要模块有哪些？
    2. 模块间如何交互？
    3. 技术栈是什么？
    """,
    run_in_background=True
)
```

### 场景3：企业代码审查系统（组合）

**需求**：自动化代码审查，按公司规范

**我的选择**：Skill + Subagent

**原因**：
```
✅ 需要标准化（Skill定义规范）
✅ 需要自动化（Subagent执行）
✅ 需要批量处理（并行审查多文件）
✅ 业务人员需要调整规范（修改Skill容易）
```

**实现**：

**第一步：定义Skill**
```markdown
# code-review-standards.md
---
name: code-review-standards
---
## Review Checklist
1. 命名：驼峰命名，语义化
2. 安全：SQL注入、XSS检查
3. 性能：复杂度<10，避免N+1
4. 测试：覆盖率>80%

## Report Template
[详细模板]
```

**第二步：启动Subagent**
```python (Pseudocode)
# 主Agent激活Skill
activate_skill("code-review-standards")

# 启动Subagent（继承Skill标准）
Task(
    subagent_type="general-purpose",
    prompt="""
    按照当前激活的code-review-standards，
    审查PR #123的所有文件。
    """,
)
```

**结果**：
- ✅ 标准统一（Skill保证）
- ✅ 自动执行（Subagent完成）
- ✅ 人类只需维护Skill（业务人员可以改）

---

## 我的决策框架（抄作业版）

经过一周的实践，我总结了一个快速决策法：

```
┌─────────────────────────────────────┐
│    问自己6个问题                     │
└─────────────────────────────────────┘

Q1: 需要理解对话历史吗？
    YES → Skill
    NO  → 继续

Q2: 需要多步骤探索吗？
    YES → Subagent
    NO  → 继续

Q3: 有多个类似任务吗？
    YES → Subagent (并行)
    NO  → 继续

Q4: 需要频繁调整标准吗？
    YES → Skill
    NO  → Subagent 或 Skill 均可

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

Q5: Skill 会不会太长，导致上下文膨胀/Token 成本过高？
    YES → 更倾向 Subagent（一次性执行，把主对话保持轻量）
    NO  → 继续

Q6: 任务是否高风险，且不能容忍黑盒执行？
    YES → Skill（人机协同）或 Skill + Subagent + 验收/回放
    NO  → Subagent

特殊情况：
如果既需要标准化，又需要自动化
→ Skill + Subagent (组合)
```

**举例**：

| 任务 | Q1历史 | Q2探索 | Q3批量 | Q4调整 | 选择 |
|------|--------|--------|--------|--------|------|
| 写技术文档 | ✅ | ❌ | ❌ | ✅ | **Skill** |
| 分析代码库 | ❌ | ✅ | ❌ | ❌ | **Subagent** |
| 审查10个PR | ❌ | ✅ | ✅ | ❌ | **Subagent** |
| 企业代码审查 | ❌ | ✅ | ✅ | ✅ | **Skill+Subagent** |

---

## 三个深刻的认知

### 认知1：Skill 不是"弱化版的 Subagent"

很多人以为：
- Skill = 简单任务
- Subagent = 复杂任务

**错！**

正确理解：
- **Skill** = 知识层（定义"什么是好"）
- **Subagent** = 执行层（完成"如何做"）

它们解决的是**不同层面**的问题。

### 认知2：Subagent 不是"万能的"

不要以为 Subagent 就一定比 Skill 好。

**Subagent 的代价**：
- ❌ 看不到对话历史（丢失上下文）
- ❌ 黑盒执行（出错了才知道）
- ❌ 需要明确的任务描述（模糊的需求会跑偏）

**什么时候不该用 Subagent**：
- 需要多轮交互澄清需求
- 需要实时调整方向
- 任务非常简单（启动开销不值得）

### 认知3：组合才是王道

**最强的 AI 工作流**：

```
┌──────────────────────────────────┐
│  Layer 1: Knowledge (Skill)      │
│  ├─ 定义标准                      │
│  ├─ 提供知识                      │
│  └─ 可维护                        │
└──────────────────────────────────┘
            ↓ (指导)
┌──────────────────────────────────┐
│  Layer 2: Execution (Subagent)   │
│  ├─ 自主执行                      │
│  ├─ 高效并行                      │
│  └─ 深度推理                      │
└──────────────────────────────────┘
            ↓ (产出)
┌──────────────────────────────────┐
│  Result: 高质量输出               │
│  ✅ 标准化 (Skill保证)            │
│  ✅ 自动化 (Subagent完成)         │
└──────────────────────────────────┘
```

**这才是企业级 AI 系统的形态。**

---

## 总结：一句话记住差异

如果只能记住一句话，记住这个：

> **Skill 是"教"，Subagent 是"用"。**

- **Skill**：教会 AI "按什么标准做事"（知识注入）
- **Subagent**：让 AI "自主完成任务"（能力封装）

**最强组合**：
- 用 Skill 沉淀你的领域知识和标准
- 用 Subagent 高效执行复杂任务
- 两者结合，打造可维护的 AI 工作流

---

## 行动建议

**如果你是新手**：
1. 第1周：只用 Skill，理解"知识注入"
2. 第2周：尝试 Subagent，体会"自主执行"
3. 第3周：组合使用，感受威力

**如果你是老手**：
1. 审视你的工作流：哪些用 Skill，哪些用 Subagent？
2. 找一个场景尝试组合模式
3. 沉淀你的领域知识到 Skill 中

---

**最后，我想说**：

理解 Skill 和 Subagent，不是为了记住定义，而是为了：
- 构建**更高质量**的 AI 工作流
- 让 AI 真正成为你的**生产力倍增器**
- 避免走弯路，少踩坑

希望这篇文章对你有帮助。如果有收获，欢迎分享给其他正在困惑的朋友。

---
